{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb164bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838344f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05f6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081df180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import html5lib\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b9756",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://realpython.github.io/fake-jobs/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "soup = bs(response.content, 'html.parser')\n",
    "first_job_title = soup.find(\"h2\", class_=\"title\").get_text()\n",
    "print(first_job_title )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73306887",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(response.content, 'html.parser')\n",
    "\n",
    "job_titles_elements = soup.find_all(\"h2\", class_=\"title\")\n",
    "    \n",
    "\n",
    "job_titles = [title.get_text() for title in job_titles_elements]\n",
    "print(job_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b5621",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = requests.get(url)\n",
    "soup = bs(response.content, 'html5lib')\n",
    "\n",
    "\n",
    "soup = bs(response.content, 'html5lib')\n",
    "    \n",
    "# job titles\n",
    "job_titles_elements = soup.find_all(\"h2\", class_=\"title\")\n",
    "job_titles = [title.get_text().strip() for title in job_titles_elements]\n",
    "\n",
    "# companies \n",
    "companies_elements = soup.find_all(\"div\", class_=\"company\")\n",
    "companies = [company.get_text().strip() for company in companies_elements]\n",
    "\n",
    "# locations\n",
    "locations_elements = soup.find_all(\"p\", class_=\"location\")\n",
    "locations = [location.get_text().strip() for location in locations_elements]\n",
    "\n",
    "# date posted\n",
    "dates_elements = soup.find_all(\"time\", datetime=True)\n",
    "dates = [date.get_text().strip() for date in dates_elements]\n",
    "\n",
    "print(job_titles, companies, locations, dates)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc3b8330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date Posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Python Developer</td>\n",
       "      <td>Payne, Roberts and Davis</td>\n",
       "      <td>Stewartbury, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy engineer</td>\n",
       "      <td>Vasquez-Davidson</td>\n",
       "      <td>Christopherville, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legal executive</td>\n",
       "      <td>Jackson, Chambers and Levy</td>\n",
       "      <td>Port Ericaburgh, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fitness centre manager</td>\n",
       "      <td>Savage-Bradley</td>\n",
       "      <td>East Seanview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product manager</td>\n",
       "      <td>Ramirez Inc</td>\n",
       "      <td>North Jamieview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Museum/gallery exhibitions officer</td>\n",
       "      <td>Nguyen, Yoder and Petty</td>\n",
       "      <td>Lake Abigail, AE</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Radiographer, diagnostic</td>\n",
       "      <td>Holder LLC</td>\n",
       "      <td>Jacobshire, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Database administrator</td>\n",
       "      <td>Yates-Ferguson</td>\n",
       "      <td>Port Susan, AE</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Furniture designer</td>\n",
       "      <td>Ortega-Lawrence</td>\n",
       "      <td>North Tiffany, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ship broker</td>\n",
       "      <td>Fuentes, Walls and Castro</td>\n",
       "      <td>Michelleville, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title                     Company  \\\n",
       "0              Senior Python Developer    Payne, Roberts and Davis   \n",
       "1                      Energy engineer            Vasquez-Davidson   \n",
       "2                      Legal executive  Jackson, Chambers and Levy   \n",
       "3               Fitness centre manager              Savage-Bradley   \n",
       "4                      Product manager                 Ramirez Inc   \n",
       "..                                 ...                         ...   \n",
       "95  Museum/gallery exhibitions officer     Nguyen, Yoder and Petty   \n",
       "96            Radiographer, diagnostic                  Holder LLC   \n",
       "97              Database administrator              Yates-Ferguson   \n",
       "98                  Furniture designer             Ortega-Lawrence   \n",
       "99                         Ship broker   Fuentes, Walls and Castro   \n",
       "\n",
       "                Location Date Posted  \n",
       "0        Stewartbury, AA  2021-04-08  \n",
       "1   Christopherville, AA  2021-04-08  \n",
       "2    Port Ericaburgh, AA  2021-04-08  \n",
       "3      East Seanview, AP  2021-04-08  \n",
       "4    North Jamieview, AP  2021-04-08  \n",
       "..                   ...         ...  \n",
       "95      Lake Abigail, AE  2021-04-08  \n",
       "96        Jacobshire, AP  2021-04-08  \n",
       "97        Port Susan, AE  2021-04-08  \n",
       "98     North Tiffany, AA  2021-04-08  \n",
       "99     Michelleville, AP  2021-04-08  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def scrape_w_nas(url):\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.content, 'html5lib')\n",
    "\n",
    "    # Initialize job boxes\n",
    "    job_titles = []\n",
    "    companies = []\n",
    "    locations = []\n",
    "    posting_dates = []\n",
    "\n",
    "    \n",
    "    job_containers = soup.find_all('div', class_='card-content')\n",
    "\n",
    "    for job in job_containers:\n",
    "        # grab bits, N/A if no dice\n",
    "        job_titles.append(job.find('h2', class_='title').text.strip() if job.find('h2', class_='title') else 'N/a')\n",
    "        companies.append(job.find('h3', class_='company').text.strip() if job.find('h3', class_='company') else 'N/a')\n",
    "        locations.append(job.find('p', class_='location').text.strip() if job.find('p', class_='location') else 'N/a')\n",
    "        posting_dates.append(job.find('time').text.strip() if job.find('time') else 'N/A')\n",
    "\n",
    "    # Create df\n",
    "    job_data = pd.DataFrame({\n",
    "        'Title': job_titles,\n",
    "        'Company': companies,\n",
    "        'Location': locations,\n",
    "        'Date Posted': posting_dates\n",
    "    })\n",
    "\n",
    "    return job_data\n",
    "\n",
    "\n",
    "scrape_w_nas = scrape_job_listings_with_placeholders(url)\n",
    "\n",
    "scrape_w_nas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0607f5",
   "metadata": {},
   "source": [
    "2.2. Next, add a column that contains the url for the \"Apply\" button. Try this in two ways.   \n",
    "    a. First, use the BeautifulSoup find_all method to extract the urls.  \n",
    "    b. Next, get those same urls in a different way. Examine the urls and see if you can spot the pattern of how they are constructed. Then, build the url using the elements you have already extracted. Ensure that the urls that you created match those that you extracted using BeautifulSoup. Warning: You will need to do some string cleaning and prep in constructing the urls this way. For example, look carefully at the urls for the \"Software Engineer (Python)\" job and the \"Scientist, research (maths)\" job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a18c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
